{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485f7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action= 'ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "s3= boto3.resource('s3')\n",
    "bucket_name= 'morgangant-bata-445-bucket'\n",
    "bucket= s3.Bucket(bucket_name)\n",
    "\n",
    "file_key1= 'churn-bigml-80.csv'\n",
    "file_key2= 'churn-bigml-20.csv'\n",
    "\n",
    "\n",
    "bucket_object1= bucket.Object(file_key1)\n",
    "file_object1= bucket_object1.get()\n",
    "file_content_stream1 = file_object1.get('Body')\n",
    "\n",
    "bucket_object2= bucket.Object(file_key2)\n",
    "file_object2 = bucket_object2.get()\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "#reading the datefile\n",
    "telecom_train = pd.read_csv(file_content_stream1)\n",
    "telecom_test= pd.read_csv(file_content_stream2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9371e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train= pd.DataFrame(telecom_train)\n",
    "telecom_test= pd.DataFrame(telecom_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3a6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating churn_numb true/false to 1/0\n",
    "telecom_train= telecom_train.assign(churn_numb= telecom_train['Churn'].astype(int))\n",
    "telecom_test= telecom_test.assign(churn_numb= telecom_test['Churn'].astype(int))\n",
    "\n",
    "#Changing International_plan yes/no to 1/0\n",
    "telecom_train['International_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "telecom_test['International_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "\n",
    "#Changing Voice_mail_plan yes/no to 1/0\n",
    "telecom_train['Voice_mail_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "telecom_test['Voice_mail_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "\n",
    "#Creating variable Total_charge\n",
    "telecom_train= telecom_train.assign(total_charge= telecom_train['Total_day_charge'] + telecom_train['Total_eve_charge'] + telecom_train['Total_night_charge']+ telecom_train['Total_intl_charge'])\n",
    "telecom_test= telecom_test.assign(total_charge= telecom_test['Total_day_charge'] + telecom_test['Total_eve_charge'] + telecom_test['Total_night_charge']+ telecom_test['Total_intl_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720f4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting x and y variables\n",
    "x = telecom_train[['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']]\n",
    "y = telecom_train['churn_numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49416d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results= list()\n",
    "ada_results= list()\n",
    "gb_results= list()\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md= RandomForestClassifier(n_estimators= 500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    rf_results.append(rf_md.feature_importances_)\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    ada_results.append(ada_md.feature_importances_)\n",
    "    \n",
    "    \n",
    "    #Building the model\n",
    "    gb_md= GradientBoostingClassifier(max_depth= 3, n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    gb_results.append(gb_md.feature_importances_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5bcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(rf_results)\n",
    "a.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "a.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc232111",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(ada_results)\n",
    "b.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "b.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(gb_results)\n",
    "c.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "c.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 4 average importances: international_plan, voice_mail_plan, total_charge, customer_service_calls\n",
    "    #I dropped Account_length since it was insignificant in 2/3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= x.drop(columns= 'Account_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b06910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary1):\n",
    "    return pd.DataFrame([row for row in product(*dictionary1.values())], \n",
    "                        columns = dictionary1.keys())\n",
    "dictionary1 = {'n_tree': [100, 500, 1000, 1500, 2000], \n",
    "                'depth': [3, 5, 7]}\n",
    "parameters1 = expand_grid(dictionary1)\n",
    "parameters1['recall']= np.nan\n",
    "parameters1['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11671c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8962bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary2):\n",
    "    return pd.DataFrame([row for row in product(*dictionary2.values())], \n",
    "                        columns = dictionary2.keys())\n",
    "dictionary2 = {'n_tree': [100, 500, 1000, 1500, 2000], \n",
    "                'depth': [3, 5, 7], \n",
    "                'learning_rate': [0.1, 0.01, 0.001]}\n",
    "parameters2 = expand_grid(dictionary2)\n",
    "parameters2['recall']= np.nan\n",
    "parameters2['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf021386",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary3):\n",
    "    return pd.DataFrame([row for row in product(*dictionary3.values())],\n",
    "                        columns = dictionary3.keys())\n",
    "dictionary3 = {'n_tree': [100, 500, 1000, 1500, 2000],\n",
    "                'depth': [3, 5, 7], \n",
    "                'learning_rate': [0.1, 0.01, 0.001]}\n",
    "parameters3 = expand_grid(dictionary3)\n",
    "parameters3['recall']= np.nan\n",
    "parameters3['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58346969",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_100_3_recall= list()\n",
    "rf_100_3_accuracy= list()\n",
    "\n",
    "rf_100_5_recall= list()\n",
    "rf_100_5_accuracy= list()\n",
    "\n",
    "rf_100_7_recall= list()\n",
    "rf_100_7_accuracy= list()\n",
    "\n",
    "rf_500_3_recall= list()\n",
    "rf_500_3_accuracy= list()\n",
    "\n",
    "rf_500_5_recall= list()\n",
    "rf_500_5_accuracy= list()\n",
    "\n",
    "rf_500_7_recall= list()\n",
    "rf_500_7_accuracy= list()\n",
    "\n",
    "rf_1000_3_accuracy= list()\n",
    "rf_1000_3_recall= list()\n",
    "\n",
    "rf_1000_5_recall= list()\n",
    "rf_1000_5_accuracy= list()\n",
    "\n",
    "rf_1000_7_recall= list()\n",
    "rf_1000_7_accuracy= list()\n",
    "\n",
    "rf_1500_3_recall= list()\n",
    "rf_1500_3_accuracy= list()\n",
    "\n",
    "rf_1500_5_recall= list()\n",
    "rf_1500_5_accuracy= list()\n",
    "\n",
    "rf_1500_7_recall= list()\n",
    "rf_1500_7_accuracy= list()\n",
    "\n",
    "rf_2000_3_recall= list()\n",
    "rf_2000_3_accuracy= list()\n",
    "\n",
    "rf_2000_5_recall= list()\n",
    "rf_2000_5_accuracy= list()\n",
    "\n",
    "rf_2000_7_recall= list()\n",
    "rf_2000_7_accuracy= list()\n",
    "\n",
    "\n",
    "\n",
    "for i in range (0,100):\n",
    "\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "    \n",
    "##### Building random forest models  \n",
    "\n",
    "    ##### 100\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md1= RandomForestClassifier(n_estimators= 100, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred1= rf_md1.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels1= np.where(rf_pred1 < .1, 0, 1)\n",
    "    rf_100_3_recall.append(recall_score(y_test, rf_labels1))\n",
    "    rf_100_3_accuracy.append(accuracy_score(y_test, rf_labels1))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md2= RandomForestClassifier(n_estimators= 100, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred2= rf_md2.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels2= np.where(rf_pred2 < .1, 0, 1)\n",
    "    rf_100_5_recall.append(recall_score(y_test, rf_labels2))\n",
    "    rf_100_5_accuracy.append(accuracy_score(y_test, rf_labels2))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md3= RandomForestClassifier(n_estimators= 100, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred3= rf_md3.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels3= np.where(rf_pred3 < .1, 0, 1)\n",
    "    rf_100_7_recall.append(recall_score(y_test, rf_labels3))\n",
    "    rf_100_7_accuracy.append(accuracy_score(y_test, rf_labels3))\n",
    "    \n",
    "    \n",
    "    ###### 500\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md4= RandomForestClassifier(n_estimators= 500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred4= rf_md4.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels4= np.where(rf_pred4 < .1, 0, 1)\n",
    "    rf_500_3_recall.append(recall_score(y_test, rf_labels4))\n",
    "    rf_500_3_accuracy.append(accuracy_score(y_test, rf_labels4))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md5= RandomForestClassifier(n_estimators= 500, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred5= rf_md5.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels5= np.where(rf_pred5 < .1, 0, 1)\n",
    "    rf_500_5_recall.append(recall_score(y_test, rf_labels5))\n",
    "    rf_500_5_accuracy.append(accuracy_score(y_test, rf_labels5))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md6= RandomForestClassifier(n_estimators= 500, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred6= rf_md6.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels6= np.where(rf_pred6 < .1, 0, 1)\n",
    "    rf_500_7_recall.append(recall_score(y_test, rf_labels6))\n",
    "    rf_500_7_accuracy.append(accuracy_score(y_test, rf_labels6))\n",
    "    \n",
    "    \n",
    "    ###### 1000\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md7= RandomForestClassifier(n_estimators= 1000, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred7= rf_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels7= np.where(rf_pred7 < .1, 0, 1)\n",
    "    rf_1000_3_recall.append(recall_score(y_test, rf_labels7))\n",
    "    rf_1000_3_accuracy.append(accuracy_score(y_test, rf_labels7))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md8= RandomForestClassifier(n_estimators= 1000, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred8= rf_md8.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels8= np.where(rf_pred8 < .1, 0, 1)\n",
    "    rf_1000_5_recall.append(recall_score(y_test, rf_labels8))\n",
    "    rf_1000_5_accuracy.append(accuracy_score(y_test, rf_labels8))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md9= RandomForestClassifier(n_estimators= 1000, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred9= rf_md9.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels9= np.where(rf_pred9 < .1, 0, 1)\n",
    "    rf_1000_7_recall.append(recall_score(y_test, rf_labels9))\n",
    "    rf_1000_7_accuracy.append(accuracy_score(y_test, rf_labels9))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####### 1500\n",
    "    \n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md10= RandomForestClassifier(n_estimators= 1500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred10= rf_md10.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels10= np.where(rf_pred10 < .1, 0, 1)\n",
    "    rf_1500_3_recall.append(recall_score(y_test, rf_labels10))\n",
    "    rf_1500_3_accuracy.append(accuracy_score(y_test, rf_labels10))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md11= RandomForestClassifier(n_estimators= 1500, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred11= rf_md11.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels11= np.where(rf_pred11 < .1, 0, 1)\n",
    "    rf_1500_5_recall.append(recall_score(y_test, rf_labels11))\n",
    "    rf_1500_5_accuracy.append(accuracy_score(y_test, rf_labels11))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md12= RandomForestClassifier(n_estimators= 1500, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred12= rf_md12.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels12= np.where(rf_pred12 < .1, 0, 1)\n",
    "    rf_1500_7_recall.append(recall_score(y_test, rf_labels12))\n",
    "    rf_1500_7_accuracy.append(accuracy_score(y_test, rf_labels12))\n",
    "    \n",
    "    \n",
    "    ##### 2000\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md13= RandomForestClassifier(n_estimators= 2000, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred13= rf_md13.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels13= np.where(rf_pred13 < .1, 0, 1)\n",
    "    rf_2000_3_recall.append(recall_score(y_test, rf_labels13))\n",
    "    rf_2000_3_accuracy.append(accuracy_score(y_test, rf_labels13))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md14= RandomForestClassifier(n_estimators= 2000, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred14= rf_md14.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels14= np.where(rf_pred14 < .1, 0, 1)\n",
    "    rf_2000_5_recall.append(recall_score(y_test, rf_labels14))\n",
    "    rf_2000_5_accuracy.append(accuracy_score(y_test, rf_labels14))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md15= RandomForestClassifier(n_estimators= 2000, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred15= rf_md15.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels15= np.where(rf_pred15 < .1, 0, 1)\n",
    "    rf_2000_7_recall.append(recall_score(y_test, rf_labels15))\n",
    "    rf_2000_7_accuracy.append(accuracy_score(y_test, rf_labels15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f878db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 100,3: 0.864871794871795\n",
      "Average Accuracy for Random Forest model 100,3: 0.871460674157303\n",
      "Average Recall for Random Forest model 100,35: 0.8650000000000001\n",
      "Average Accuracy for Random Forest model 100,5: 0.8752434456928836\n",
      "Average Recall for Random Forest model 100,7: 0.863846153846154\n",
      "Average Accuracy for Random Forest model 100,7: 0.9015730337078653\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 100,3:', np.mean(rf_100_3_recall))\n",
    "print('Average Accuracy for Random Forest model 100,3:', np.mean(rf_100_3_accuracy))\n",
    "print('Average Recall for Random Forest model 100,35:', np.mean(rf_100_5_recall))\n",
    "print('Average Accuracy for Random Forest model 100,5:', np.mean(rf_100_5_accuracy))\n",
    "print('Average Recall for Random Forest model 100,7:', np.mean(rf_100_7_recall))\n",
    "print('Average Accuracy for Random Forest model 100,7:', np.mean(rf_100_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3846497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 500,3: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 500,3: 0.871516853932584\n",
      "Average Recall for Random Forest model 500,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 500,5: 0.8732771535580521\n",
      "Average Recall for Random Forest model 500,7: 0.8642307692307694\n",
      "Average Accuracy for Random Forest model 500,7: 0.9033333333333335\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 500,3:', np.mean(rf_500_3_recall))\n",
    "print('Average Accuracy for Random Forest model 500,3:', np.mean(rf_500_3_accuracy))\n",
    "print('Average Recall for Random Forest model 500,35:', np.mean(rf_500_5_recall))\n",
    "print('Average Accuracy for Random Forest model 500,5:', np.mean(rf_500_5_accuracy))\n",
    "print('Average Recall for Random Forest model 500,7:', np.mean(rf_500_7_recall))\n",
    "print('Average Accuracy for Random Forest model 500,7:', np.mean(rf_500_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc06fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 1000,3: 0.8650000000000001\n",
      "Average Accuracy for Random Forest model 1000,3: 0.8715355805243443\n",
      "Average Recall for Random Forest model 1000,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 1000,5: 0.8729962546816477\n",
      "Average Recall for Random Forest model 1000,7: 0.8644871794871796\n",
      "Average Accuracy for Random Forest model 1000,7: 0.902921348314607\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 1000,3:', np.mean(rf_1000_3_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,3:', np.mean(rf_1000_3_accuracy))\n",
    "print('Average Recall for Random Forest model 1000,35:', np.mean(rf_1000_5_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,5:', np.mean(rf_1000_5_accuracy))\n",
    "print('Average Recall for Random Forest model 1000,7:', np.mean(rf_1000_7_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,7:', np.mean(rf_1000_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c50232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 1500,3: 0.8646153846153847\n",
      "Average Accuracy for Random Forest model 1500,3: 0.8715543071161046\n",
      "Average Recall for Random Forest model 1500,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 1500,5: 0.8728651685393255\n",
      "Average Recall for Random Forest model 1500,7: 0.8643589743589745\n",
      "Average Accuracy for Random Forest model 1500,7: 0.903239700374532\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 1500,3:', np.mean(rf_1500_3_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,3:', np.mean(rf_1500_3_accuracy))\n",
    "print('Average Recall for Random Forest model 1500,35:', np.mean(rf_1500_5_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,5:', np.mean(rf_1500_5_accuracy))\n",
    "print('Average Recall for Random Forest model 1500,7:', np.mean(rf_1500_7_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,7:', np.mean(rf_1500_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107509d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Recall for Random Forest model 2000,3:', np.mean(rf_2000_3_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,3:', np.mean(rf_2000_3_accuracy))\n",
    "print('Average Recall for Random Forest model 2000,35:', np.mean(rf_2000_5_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,5:', np.mean(rf_2000_5_accuracy))\n",
    "print('Average Recall for Random Forest model 2000,7:', np.mean(rf_2000_7_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,7:', np.mean(rf_2000_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebf34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_100_3_001_recall= list()\n",
    "ada_100_3_001_accuracy= list()\n",
    "ada_100_3_01_recall= list()\n",
    "ada_100_3_01_accuracy= list()\n",
    "ada_100_3_1_recall= list()\n",
    "ada_100_3_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_100_5_001_recall= list()\n",
    "ada_100_5_001_accuracy= list()\n",
    "ada_100_5_01_recall= list()\n",
    "ada_100_5_01_accuracy= list()\n",
    "ada_100_5_1_recall= list()\n",
    "ada_100_5_1_accuracy= list()\n",
    "\n",
    "ada_100_7_001_recall= list()\n",
    "ada_100_7_001_accuracy= list()\n",
    "ada_100_7_01_recall= list()\n",
    "ada_100_7_01_accuracy= list()\n",
    "ada_100_7_1_recall= list()\n",
    "ada_100_7_1_accuracy= list()\n",
    "\n",
    "ada_500_3_001_recall= list()\n",
    "ada_500_3_001_accuracy= list()\n",
    "ada_500_3_01_recall= list()\n",
    "ada_500_3_01_accuracy= list()\n",
    "ada_500_3_1_recall= list()\n",
    "ada_500_3_1_accuracy= list()\n",
    "\n",
    "ada_500_5_001_recall= list()\n",
    "ada_500_5_001_accuracy= list()\n",
    "ada_500_5_01_recall= list()\n",
    "ada_500_5_01_accuracy= list()\n",
    "ada_500_5_1_recall= list()\n",
    "ada_500_5_1_accuracy= list()\n",
    "\n",
    "ada_500_7_001_recall= list()\n",
    "ada_500_7_001_accuracy= list()\n",
    "ada_500_7_01_recall= list()\n",
    "ada_500_7_01_accuracy= list()\n",
    "ada_500_7_1_recall= list()\n",
    "ada_500_7_1_accuracy= list()\n",
    "\n",
    "ada_1000_3_001_accuracy= list()\n",
    "ada_1000_3_001_recall= list()\n",
    "ada_1000_3_01_accuracy= list()\n",
    "ada_1000_3_01_recall= list()\n",
    "ada_1000_3_1_accuracy= list()\n",
    "ada_1000_3_1_recall= list()\n",
    "\n",
    "ada_1000_5_001_recall= list()\n",
    "ada_1000_5_001_accuracy= list()\n",
    "ada_1000_5_01_recall= list()\n",
    "ada_1000_5_01_accuracy= list()\n",
    "ada_1000_5_1_recall= list()\n",
    "ada_1000_5_1_accuracy= list()\n",
    "\n",
    "ada_1000_7_001_recall= list()\n",
    "ada_1000_7_001_accuracy= list()\n",
    "ada_1000_7_01_recall= list()\n",
    "ada_1000_7_01_accuracy= list()\n",
    "ada_1000_7_1_recall= list()\n",
    "ada_1000_7_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_1500_3_001_recall= list()\n",
    "ada_1500_3_001_accuracy= list()\n",
    "ada_1500_3_01_recall= list()\n",
    "ada_1500_3_01_accuracy= list()\n",
    "ada_1500_3_1_recall= list()\n",
    "ada_1500_3_1_accuracy= list()\n",
    "\n",
    "ada_1500_5_001_recall= list()\n",
    "ada_1500_5_001_accuracy= list()\n",
    "ada_1500_5_01_recall= list()\n",
    "ada_1500_5_01_accuracy= list()\n",
    "ada_1500_5_1_recall= list()\n",
    "ada_1500_5_1_accuracy= list()\n",
    "\n",
    "ada_1500_7_001_recall= list()\n",
    "ada_1500_7_001_accuracy= list()\n",
    "ada_1500_7_01_recall= list()\n",
    "ada_1500_7_01_accuracy= list()\n",
    "ada_1500_7_1_recall= list()\n",
    "ada_1500_7_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_2000_3_001_recall= list()\n",
    "ada_2000_3_001_accuracy= list()\n",
    "ada_2000_3_01_recall= list()\n",
    "ada_2000_3_01_accuracy= list()\n",
    "ada_2000_3_1_recall= list()\n",
    "ada_2000_3_1_accuracy= list()\n",
    "\n",
    "ada_2000_5_001_recall= list()\n",
    "ada_2000_5_001_accuracy= list()\n",
    "ada_2000_5_01_recall= list()\n",
    "ada_2000_5_01_accuracy= list()\n",
    "ada_2000_5_1_recall= list()\n",
    "ada_2000_5_1_accuracy= list()\n",
    "\n",
    "ada_2000_7_001_recall= list()\n",
    "ada_2000_7_001_accuracy= list()\n",
    "ada_2000_7_01_recall= list()\n",
    "ada_2000_7_01_accuracy= list()\n",
    "ada_2000_7_1_recall= list()\n",
    "ada_2000_7_1_accuracy= list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59faa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building Ada models\n",
    "\n",
    "for i in range(0,100):\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "\n",
    "#### 100,3    \n",
    "    #Building the model\n",
    "    ada_md1= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred1= ada_md1.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels1= np.where(ada_pred1 < .1, 0, 1)\n",
    "    ada_100_3_001_recall.append(recall_score(y_test, ada_labels1))\n",
    "    ada_100_3_001_accuracy.append(accuracy_score(y_test, ada_labels1))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md2= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred2= ada_md2.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels2= np.where(ada_pred2 < .1, 0, 1)\n",
    "    ada_100_3_01_recall.append(recall_score(y_test, ada_labels2))\n",
    "    ada_100_3_01_accuracy.append(accuracy_score(y_test, ada_labels2))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md3= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred3= ada_md3.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels3= np.where(ada_pred3 < .1, 0, 1)\n",
    "    ada_100_3_1_recall.append(recall_score(y_test, ada_labels3))\n",
    "    ada_100_3_1_accuracy.append(accuracy_score(y_test, ada_labels3))\n",
    "    \n",
    "    \n",
    "### 100,5\n",
    "    #Building the model\n",
    "    ada_md4= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred4= ada_md4.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels4= np.where(ada_pred1 < .1, 0, 1)\n",
    "    ada_100_5_001_recall.append(recall_score(y_test, ada_labels4))\n",
    "    ada_100_5_001_accuracy.append(accuracy_score(y_test, ada_labels4))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md5= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred5= ada_md5.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels5= np.where(ada_pred5 < .1, 0, 1)\n",
    "    ada_100_5_01_recall.append(recall_score(y_test, ada_labels5))\n",
    "    ada_100_5_01_accuracy.append(accuracy_score(y_test, ada_labels5))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md6= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred6= ada_md6.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels6= np.where(ada_pred6 < .1, 0, 1)\n",
    "    ada_100_5_1_recall.append(recall_score(y_test, ada_labels6))\n",
    "    ada_100_5_1_accuracy.append(accuracy_score(y_test, ada_labels6))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 100,7\n",
    "    #Building the model\n",
    "    ada_md7= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred7= ada_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels7= np.where(ada_pred7 < .1, 0, 1)\n",
    "    ada_100_7_001_recall.append(recall_score(y_test, ada_labels7))\n",
    "    ada_100_7_001_accuracy.append(accuracy_score(y_test, ada_labels7))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md8= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred8= ada_md8.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels8= np.where(ada_pred8 < .1, 0, 1)\n",
    "    ada_100_7_01_recall.append(recall_score(y_test, ada_labels8))\n",
    "    ada_100_7_01_accuracy.append(accuracy_score(y_test, ada_labels8))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md9= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred9= ada_md9.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels9= np.where(ada_pred9 < .1, 0, 1)\n",
    "    ada_100_7_1_recall.append(recall_score(y_test, ada_labels9))\n",
    "    ada_100_7_1_accuracy.append(accuracy_score(y_test, ada_labels9))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #### 500,3    \n",
    "    #Building the model\n",
    "    ada_md10= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred10= ada_md10.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels10= np.where(ada_pred10 < .1, 0, 1)\n",
    "    ada_500_3_001_recall.append(recall_score(y_test, ada_labels10))\n",
    "    ada_500_3_001_accuracy.append(accuracy_score(y_test, ada_labels10))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md11= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred11= ada_md11.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels11= np.where(ada_pred11 < .1, 0, 1)\n",
    "    ada_500_3_01_recall.append(recall_score(y_test, ada_labels11))\n",
    "    ada_500_3_01_accuracy.append(accuracy_score(y_test, ada_labels11))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md12= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators=500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred12= ada_md12.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels12= np.where(ada_pred12 < .1, 0, 1)\n",
    "    ada_500_3_1_recall.append(recall_score(y_test, ada_labels12))\n",
    "    ada_500_3_1_accuracy.append(accuracy_score(y_test, ada_labels12))\n",
    "    \n",
    "    \n",
    "### 500,5\n",
    "    #Building the model\n",
    "    ada_md13= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred13= ada_md13.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels13= np.where(ada_pred13 < .1, 0, 1)\n",
    "    ada_500_5_001_recall.append(recall_score(y_test, ada_labels13))\n",
    "    ada_500_5_001_accuracy.append(accuracy_score(y_test, ada_labels13))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md14= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred14= ada_md14.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels14= np.where(ada_pred14 < .1, 0, 1)\n",
    "    ada_500_5_01_recall.append(recall_score(y_test, ada_labels14))\n",
    "    ada_500_5_01_accuracy.append(accuracy_score(y_test, ada_labels14))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md15= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred15= ada_md15.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels15= np.where(ada_pred6 < .1, 0, 1)\n",
    "    ada_500_5_1_recall.append(recall_score(y_test, ada_labels15))\n",
    "    ada_500_5_1_accuracy.append(accuracy_score(y_test, ada_labels15))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 500,7\n",
    "    #Building the model\n",
    "    ada_md16= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred16= ada_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels16= np.where(ada_pred16 < .1, 0, 1)\n",
    "    ada_500_7_001_recall.append(recall_score(y_test, ada_labels16))\n",
    "    ada_500_7_001_accuracy.append(accuracy_score(y_test, ada_labels16))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md17= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred17= ada_md17.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels17= np.where(ada_pred17 < .1, 0, 1)\n",
    "    ada_500_7_01_recall.append(recall_score(y_test, ada_labels17))\n",
    "    ada_500_7_01_accuracy.append(accuracy_score(y_test, ada_labels17))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md45= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred45= ada_md45.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels45= np.where(ada_pred45 < .1, 0, 1)\n",
    "    ada_500_7_1_recall.append(recall_score(y_test, ada_labels45))\n",
    "    ada_500_7_1_accuracy.append(accuracy_score(y_test, ada_labels45))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### 1000,3    \n",
    "    #Building the model\n",
    "    ada_md18= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred18= ada_md18.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels18= np.where(ada_pred18 < .1, 0, 1)\n",
    "    ada_1000_3_001_recall.append(recall_score(y_test, ada_labels18))\n",
    "    ada_1000_3_001_accuracy.append(accuracy_score(y_test, ada_labels18))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md19= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred19= ada_md19.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels19= np.where(ada_pred19 < .1, 0, 1)\n",
    "    ada_1000_3_01_recall.append(recall_score(y_test, ada_labels19))\n",
    "    ada_1000_3_01_accuracy.append(accuracy_score(y_test, ada_labels19))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md20= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred20= ada_md20.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels20= np.where(ada_pred20 < .1, 0, 1)\n",
    "    ada_1000_3_1_recall.append(recall_score(y_test, ada_labels20))\n",
    "    ada_1000_3_1_accuracy.append(accuracy_score(y_test, ada_labels20))\n",
    "    \n",
    "    \n",
    "### 1000,5\n",
    "    #Building the model\n",
    "    ada_md21= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred21= ada_md21.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels21= np.where(ada_pred21 < .1, 0, 1)\n",
    "    ada_1000_5_001_recall.append(recall_score(y_test, ada_labels21))\n",
    "    ada_1000_5_001_accuracy.append(accuracy_score(y_test, ada_labels21))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md22= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred22= ada_md22.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels22= np.where(ada_pred22 < .1, 0, 1)\n",
    "    ada_500_5_01_recall.append(recall_score(y_test, ada_labels22))\n",
    "    ada_500_5_01_accuracy.append(accuracy_score(y_test, ada_labels22))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md23= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred23= ada_md23.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels23= np.where(ada_pred23 < .1, 0, 1)\n",
    "    ada_500_5_1_recall.append(recall_score(y_test, ada_labels23))\n",
    "    ada_500_5_1_accuracy.append(accuracy_score(y_test, ada_labels23))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 1000,7\n",
    "    #Building the model\n",
    "    ada_md24= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred24= ada_md24.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels24= np.where(ada_pred24 < .1, 0, 1)\n",
    "    ada_1000_7_001_recall.append(recall_score(y_test, ada_labels24))\n",
    "    ada_1000_7_001_accuracy.append(accuracy_score(y_test, ada_labels24))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md25= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred25= ada_md25.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels25= np.where(ada_pred25 < .1, 0, 1)\n",
    "    ada_1000_7_01_recall.append(recall_score(y_test, ada_labels25))\n",
    "    ada_1000_7_01_accuracy.append(accuracy_score(y_test, ada_labels25))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md26= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred26= ada_md26.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels26= np.where(ada_pred26 < .1, 0, 1)\n",
    "    ada_1000_7_1_recall.append(recall_score(y_test, ada_labels26))\n",
    "    ada_1000_7_1_accuracy.append(accuracy_score(y_test, ada_labels26))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### 1500,3    \n",
    "    #Building the model\n",
    "    ada_md27= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred27= ada_md27.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels27= np.where(ada_pred27 < .1, 0, 1)\n",
    "    ada_1500_3_001_recall.append(recall_score(y_test, ada_labels27))\n",
    "    ada_1500_3_001_accuracy.append(accuracy_score(y_test, ada_labels27))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md28= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred28= ada_md28.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels28= np.where(ada_pred28 < .1, 0, 1)\n",
    "    ada_1500_3_01_recall.append(recall_score(y_test, ada_labels28))\n",
    "    ada_1500_3_01_accuracy.append(accuracy_score(y_test, ada_labels28))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md29= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred29= ada_md29.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels29= np.where(ada_pred29 < .1, 0, 1)\n",
    "    ada_1500_3_1_recall.append(recall_score(y_test, ada_labels29))\n",
    "    ada_1500_3_1_accuracy.append(accuracy_score(y_test, ada_labels29))\n",
    "    \n",
    "    \n",
    "### 1500,5\n",
    "    #Building the model\n",
    "    ada_md30= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred30= ada_md30.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels30= np.where(ada_pred30 < .1, 0, 1)\n",
    "    ada_1500_5_001_recall.append(recall_score(y_test, ada_labels30))\n",
    "    ada_1500_5_001_accuracy.append(accuracy_score(y_test, ada_labels30))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md31= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred31= ada_md31.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels31= np.where(ada_pred31 < .1, 0, 1)\n",
    "    ada_1500_5_01_recall.append(recall_score(y_test, ada_labels31))\n",
    "    ada_1500_5_01_accuracy.append(accuracy_score(y_test, ada_labels31))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md32= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred32= ada_md32.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels32= np.where(ada_pred32 < .1, 0, 1)\n",
    "    ada_1500_5_1_recall.append(recall_score(y_test, ada_labels32))\n",
    "    ada_1500_5_1_accuracy.append(accuracy_score(y_test, ada_labels32))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 1500,7\n",
    "    #Building the model\n",
    "    ada_md33= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred33= ada_md33.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels33= np.where(ada_pred33 < .1, 0, 1)\n",
    "    ada_1500_7_001_recall.append(recall_score(y_test, ada_labels33))\n",
    "    ada_1500_7_001_accuracy.append(accuracy_score(y_test, ada_labels33))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md34= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred34= ada_md34.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels34= np.where(ada_pred34 < .1, 0, 1)\n",
    "    ada_1500_7_01_recall.append(recall_score(y_test, ada_labels34))\n",
    "    ada_1500_7_01_accuracy.append(accuracy_score(y_test, ada_labels34))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md35= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred35= ada_md35.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels35= np.where(ada_pred35 < .1, 0, 1)\n",
    "    ada_1500_7_1_recall.append(recall_score(y_test, ada_labels35))\n",
    "    ada_1500_7_1_accuracy.append(accuracy_score(y_test, ada_labels35))   \n",
    "    \n",
    "    \n",
    "#### 2000,3  \n",
    "    #Building the model\n",
    "    ada_md36= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred36= ada_md36.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels36= np.where(ada_pred36 < .1, 0, 1)\n",
    "    ada_1500_3_001_recall.append(recall_score(y_test, ada_labels36))\n",
    "    ada_1500_3_001_accuracy.append(accuracy_score(y_test, ada_labels36))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md37= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred37= ada_md37.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels37= np.where(ada_pred37 < .1, 0, 1)\n",
    "    ada_2000_3_01_recall.append(recall_score(y_test, ada_labels37))\n",
    "    ada_2000_3_01_accuracy.append(accuracy_score(y_test, ada_labels37))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md38= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred38= ada_md38.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels38= np.where(ada_pred38 < .1, 0, 1)\n",
    "    ada_2000_3_1_recall.append(recall_score(y_test, ada_labels38))\n",
    "    ada_2000_3_1_accuracy.append(accuracy_score(y_test, ada_labels38))\n",
    "    \n",
    "    \n",
    "### 2000,5\n",
    "    #Building the model\n",
    "    ada_md39= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred39= ada_md39.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels39= np.where(ada_pred39 < .1, 0, 1)\n",
    "    ada_2000_5_001_recall.append(recall_score(y_test, ada_labels39))\n",
    "    ada_2000_5_001_accuracy.append(accuracy_score(y_test, ada_labels39))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md40= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred40= ada_md40.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels40= np.where(ada_pred40 < .1, 0, 1)\n",
    "    ada_2000_5_01_recall.append(recall_score(y_test, ada_labels40))\n",
    "    ada_2000_5_01_accuracy.append(accuracy_score(y_test, ada_labels40))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md41= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred41= ada_md41.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels41= np.where(ada_pred41 < .1, 0, 1)\n",
    "    ada_2000_5_1_recall.append(recall_score(y_test, ada_labels41))\n",
    "    ada_2000_5_1_accuracy.append(accuracy_score(y_test, ada_labels41))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 2000,7\n",
    "    #Building the model\n",
    "    ada_md42= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred42= ada_md42.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels42= np.where(ada_pred42 < .1, 0, 1)\n",
    "    ada_2000_7_001_recall.append(recall_score(y_test, ada_labels42))\n",
    "    ada_2000_7_001_accuracy.append(accuracy_score(y_test, ada_labels42))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md43= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred43= ada_md43.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels43= np.where(ada_pred34 < .1, 0, 1)\n",
    "    ada_2000_7_01_recall.append(recall_score(y_test, ada_labels43))\n",
    "    ada_2000_7_01_accuracy.append(accuracy_score(y_test, ada_labels43))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md44= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred44= ada_md44.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels44= np.where(ada_pred44 < .1, 0, 1)\n",
    "    ada_2000_7_1_recall.append(recall_score(y_test, ada_labels44))\n",
    "    ada_2000_7_1_accuracy.append(accuracy_score(y_test, ada_labels44))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49483009",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Recall for Ada model 2000,7,.1:', np.mean(ada_2000_7_1_recall))\n",
    "print('Average Accuracy for Ada model 2000, 7,.1:', np.mean(ada_2000_7_1_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

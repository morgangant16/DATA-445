{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3689aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action= 'ignore', category='SettingWithCopyWarning')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,  GradientBoostingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "s3= boto3.resource('s3')\n",
    "bucket_name= 'morgangant-bata-445-bucket'\n",
    "bucket= s3.Bucket(bucket_name)\n",
    "\n",
    "file_key1= 'churn-bigml-80.csv'\n",
    "file_key2= 'churn-bigml-20.csv'\n",
    "\n",
    "\n",
    "bucket_object1= bucket.Object(file_key1)\n",
    "file_object1= bucket_object1.get()\n",
    "file_content_stream1 = file_object1.get('Body')\n",
    "\n",
    "bucket_object2= bucket.Object(file_key2)\n",
    "file_object2 = bucket_object2.get()\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "#reading the datefile\n",
    "telecom_train = pd.read_csv(file_content_stream1)\n",
    "telecom_test= pd.read_csv(file_content_stream2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91a225d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train= pd.DataFrame(telecom_train)\n",
    "telecom_test= pd.DataFrame(telecom_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e424b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating churn_numb true/false to 1/0\n",
    "telecom_train= telecom_train.assign(churn_numb= telecom_train['Churn'].astype(int))\n",
    "telecom_test= telecom_test.assign(churn_numb= telecom_test['Churn'].astype(int))\n",
    "\n",
    "#Changing International_plan yes/no to 1/0\n",
    "telecom_train['International_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "telecom_test['International_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "\n",
    "#Changing Voice_mail_plan yes/no to 1/0\n",
    "telecom_train['Voice_mail_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "telecom_test['Voice_mail_plan'].replace(['Yes', 'No'], [1,0], inplace= True)\n",
    "\n",
    "#Creating variable Total_charge\n",
    "telecom_train= telecom_train.assign(total_charge= telecom_train['Total_day_charge'] + telecom_train['Total_eve_charge'] + telecom_train['Total_night_charge']+ telecom_train['Total_intl_charge'])\n",
    "telecom_test= telecom_test.assign(total_charge= telecom_test['Total_day_charge'] + telecom_test['Total_eve_charge'] + telecom_test['Total_night_charge']+ telecom_test['Total_intl_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43df35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting x and y variables\n",
    "x = telecom_train[['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']]\n",
    "y = telecom_train['churn_numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f83478",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results= list()\n",
    "ada_results= list()\n",
    "gb_results= list()\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md= RandomForestClassifier(n_estimators= 500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    rf_results.append(rf_md.feature_importances_)\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    ada_results.append(ada_md.feature_importances_)\n",
    "    \n",
    "    \n",
    "    #Building the model\n",
    "    gb_md= GradientBoostingClassifier(max_depth= 3, n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Extracting the feature importances\n",
    "    gb_results.append(gb_md.feature_importances_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "289ee88b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31346/3086522109.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Account_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'International_plan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Voice_mail_plan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_charge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Customer_service_calls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_results' is not defined"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(rf_results)\n",
    "a.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "a.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44138657",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(ada_results)\n",
    "b.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "b.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e103f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(gb_results)\n",
    "c.columns= ['Account_length', 'International_plan', 'Voice_mail_plan', 'total_charge', 'Customer_service_calls']\n",
    "c.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 4 average importances: international_plan, voice_mail_plan, total_charge, customer_service_calls\n",
    "    #I dropped Account_length since it was insignificant in 2/3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c329928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= x.drop(columns= 'Account_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2740f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary1):\n",
    "    return pd.DataFrame([row for row in product(*dictionary1.values())], \n",
    "                        columns = dictionary1.keys())\n",
    "dictionary1 = {'n_tree': [100, 500, 1000, 1500, 2000], \n",
    "                'depth': [3, 5, 7]}\n",
    "parameters1 = expand_grid(dictionary1)\n",
    "parameters1['recall']= np.nan\n",
    "parameters1['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9db091a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>depth</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1500</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tree  depth  recall  accuracy\n",
       "0      100      3     NaN       NaN\n",
       "1      100      5     NaN       NaN\n",
       "2      100      7     NaN       NaN\n",
       "3      500      3     NaN       NaN\n",
       "4      500      5     NaN       NaN\n",
       "5      500      7     NaN       NaN\n",
       "6     1000      3     NaN       NaN\n",
       "7     1000      5     NaN       NaN\n",
       "8     1000      7     NaN       NaN\n",
       "9     1500      3     NaN       NaN\n",
       "10    1500      5     NaN       NaN\n",
       "11    1500      7     NaN       NaN\n",
       "12    2000      3     NaN       NaN\n",
       "13    2000      5     NaN       NaN\n",
       "14    2000      7     NaN       NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cb580e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary2):\n",
    "    return pd.DataFrame([row for row in product(*dictionary2.values())], \n",
    "                        columns = dictionary2.keys())\n",
    "dictionary2 = {'n_tree': [100, 500, 1000, 1500, 2000], \n",
    "                'depth': [3, 5, 7], \n",
    "                'learning_rate': [0.1, 0.01, 0.001]}\n",
    "parameters2 = expand_grid(dictionary2)\n",
    "parameters2['recall']= np.nan\n",
    "parameters2['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7a1d4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tree</th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1500</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tree  depth  learning_rate  recall  accuracy\n",
       "0      100      3          0.100     NaN       NaN\n",
       "1      100      3          0.010     NaN       NaN\n",
       "2      100      3          0.001     NaN       NaN\n",
       "3      100      5          0.100     NaN       NaN\n",
       "4      100      5          0.010     NaN       NaN\n",
       "5      100      5          0.001     NaN       NaN\n",
       "6      100      7          0.100     NaN       NaN\n",
       "7      100      7          0.010     NaN       NaN\n",
       "8      100      7          0.001     NaN       NaN\n",
       "9      500      3          0.100     NaN       NaN\n",
       "10     500      3          0.010     NaN       NaN\n",
       "11     500      3          0.001     NaN       NaN\n",
       "12     500      5          0.100     NaN       NaN\n",
       "13     500      5          0.010     NaN       NaN\n",
       "14     500      5          0.001     NaN       NaN\n",
       "15     500      7          0.100     NaN       NaN\n",
       "16     500      7          0.010     NaN       NaN\n",
       "17     500      7          0.001     NaN       NaN\n",
       "18    1000      3          0.100     NaN       NaN\n",
       "19    1000      3          0.010     NaN       NaN\n",
       "20    1000      3          0.001     NaN       NaN\n",
       "21    1000      5          0.100     NaN       NaN\n",
       "22    1000      5          0.010     NaN       NaN\n",
       "23    1000      5          0.001     NaN       NaN\n",
       "24    1000      7          0.100     NaN       NaN\n",
       "25    1000      7          0.010     NaN       NaN\n",
       "26    1000      7          0.001     NaN       NaN\n",
       "27    1500      3          0.100     NaN       NaN\n",
       "28    1500      3          0.010     NaN       NaN\n",
       "29    1500      3          0.001     NaN       NaN\n",
       "30    1500      5          0.100     NaN       NaN\n",
       "31    1500      5          0.010     NaN       NaN\n",
       "32    1500      5          0.001     NaN       NaN\n",
       "33    1500      7          0.100     NaN       NaN\n",
       "34    1500      7          0.010     NaN       NaN\n",
       "35    1500      7          0.001     NaN       NaN\n",
       "36    2000      3          0.100     NaN       NaN\n",
       "37    2000      3          0.010     NaN       NaN\n",
       "38    2000      3          0.001     NaN       NaN\n",
       "39    2000      5          0.100     NaN       NaN\n",
       "40    2000      5          0.010     NaN       NaN\n",
       "41    2000      5          0.001     NaN       NaN\n",
       "42    2000      7          0.100     NaN       NaN\n",
       "43    2000      7          0.010     NaN       NaN\n",
       "44    2000      7          0.001     NaN       NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06321a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(dictionary3):\n",
    "    return pd.DataFrame([row for row in product(*dictionary3.values())],\n",
    "                        columns = dictionary3.keys())\n",
    "dictionary3 = {'n_tree': [100, 500, 1000, 1500, 2000],\n",
    "                'depth': [3, 5, 7], \n",
    "                'learning_rate': [0.1, 0.01, 0.001]}\n",
    "parameters3 = expand_grid(dictionary3)\n",
    "parameters3['recall']= np.nan\n",
    "parameters3['accuracy']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901e2ba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "issubclass() arg 2 must be a class or tuple of classes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31346/1346317944.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#changing liklihoods to labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrf_labels1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_pred1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mparameters1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_labels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mparameters1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_labels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m         \u001b[0mcacher_needs_updating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"referent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   3933\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettingWithCopyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3935\u001b[0;31m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettingWithCopyWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3937\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 2 must be a class or tuple of classes"
     ]
    }
   ],
   "source": [
    "for i in range (0,10):\n",
    "\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "    \n",
    "\n",
    "    ##### Random Forest\n",
    "    for k in range(len(parameters1)):\n",
    "        #Buidling the model\n",
    "        rf_md1= RandomForestClassifier(n_estimators= parameters1['n_tree'][k], max_depth=parameters1['depth'][k]).fit(x_train, y_train)\n",
    "        #Predicting on the model\n",
    "        rf_pred1= rf_md1.predict_proba(x_test)[:,1]\n",
    "        #changing liklihoods to labels \n",
    "        rf_labels1= np.where(rf_pred1 < .1, 0, 1)\n",
    "        parameters1['recall'][k]= recall_score(y_test, rf_labels1)\n",
    "        parameters1['accuracy'][k]= accuracy_score(y_test, rf_labels1)\n",
    "        \n",
    "    #### Ada Boost    \n",
    "    for m in range(len(paramters2)):\n",
    "        #Building the model\n",
    "        ada_md1= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= parameters2['n_tree'][m]), n_estimators= parameters2['depth'][m], learning_rate= parameters2['learning_rate'][m]).fit(x_train, y_train)\n",
    "        #Predicting on the model\n",
    "        ada_pred1= ada_md1.predict_proba(x_test)[:,1]\n",
    "        #changing liklihoods to labels \n",
    "        ada_labels1= np.where(ada_pred1 < .1, 0, 1)\n",
    "        paramters2['recall'][m]= recall_score(y_test, ada_labels1)\n",
    "        paramters2['accuracy'][m]= accuracy_score(y_test, ada_labels1)\n",
    "\n",
    "    ### Gradient Boost\n",
    "    for n in range(len(paramters3)):\n",
    "        #Building the model\n",
    "        gb_md= GradientBoostingClassifier(max_depth= parameters3['depth'][n], n_estimators= parameters3['n_tree'][n], learning_rate= parameters3['learning_rate'][n]).fit(x_train, y_train)\n",
    "        #Predicting on the model\n",
    "        gb_pred= gb_md.predict_proba(x_test)[:,1]\n",
    "        #changing liklihoods to labels \n",
    "        gb_labels= np.where(gb_pred < .1, 0, 1)\n",
    "        paramters3['recall'][n]= recall_score(y_test, gb_labels)\n",
    "        paramters3['accuracy'][n] = accuracy_score(y_test, gb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a393e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_100_3_recall= list()\n",
    "rf_100_3_accuracy= list()\n",
    "\n",
    "rf_100_5_recall= list()\n",
    "rf_100_5_accuracy= list()\n",
    "\n",
    "rf_100_7_recall= list()\n",
    "rf_100_7_accuracy= list()\n",
    "\n",
    "rf_500_3_recall= list()\n",
    "rf_500_3_accuracy= list()\n",
    "\n",
    "rf_500_5_recall= list()\n",
    "rf_500_5_accuracy= list()\n",
    "\n",
    "rf_500_7_recall= list()\n",
    "rf_500_7_accuracy= list()\n",
    "\n",
    "rf_1000_3_accuracy= list()\n",
    "rf_1000_3_recall= list()\n",
    "\n",
    "rf_1000_5_recall= list()\n",
    "rf_1000_5_accuracy= list()\n",
    "\n",
    "rf_1000_7_recall= list()\n",
    "rf_1000_7_accuracy= list()\n",
    "\n",
    "rf_1500_3_recall= list()\n",
    "rf_1500_3_accuracy= list()\n",
    "\n",
    "rf_1500_5_recall= list()\n",
    "rf_1500_5_accuracy= list()\n",
    "\n",
    "rf_1500_7_recall= list()\n",
    "rf_1500_7_accuracy= list()\n",
    "\n",
    "rf_2000_3_recall= list()\n",
    "rf_2000_3_accuracy= list()\n",
    "\n",
    "rf_2000_5_recall= list()\n",
    "rf_2000_5_accuracy= list()\n",
    "\n",
    "rf_2000_7_recall= list()\n",
    "rf_2000_7_accuracy= list()\n",
    "\n",
    "\n",
    "\n",
    "for i in range (0,100):\n",
    "\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "    \n",
    "##### Building random forest models  \n",
    "\n",
    "    ##### 100\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md1= RandomForestClassifier(n_estimators= 100, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred1= rf_md1.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels1= np.where(rf_pred1 < .1, 0, 1)\n",
    "    rf_100_3_recall.append(recall_score(y_test, rf_labels1))\n",
    "    rf_100_3_accuracy.append(accuracy_score(y_test, rf_labels1))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md2= RandomForestClassifier(n_estimators= 100, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred2= rf_md2.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels2= np.where(rf_pred2 < .1, 0, 1)\n",
    "    rf_100_5_recall.append(recall_score(y_test, rf_labels2))\n",
    "    rf_100_5_accuracy.append(accuracy_score(y_test, rf_labels2))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md3= RandomForestClassifier(n_estimators= 100, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred3= rf_md3.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels3= np.where(rf_pred3 < .1, 0, 1)\n",
    "    rf_100_7_recall.append(recall_score(y_test, rf_labels3))\n",
    "    rf_100_7_accuracy.append(accuracy_score(y_test, rf_labels3))\n",
    "    \n",
    "    \n",
    "    ###### 500\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md4= RandomForestClassifier(n_estimators= 500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred4= rf_md4.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels4= np.where(rf_pred4 < .1, 0, 1)\n",
    "    rf_500_3_recall.append(recall_score(y_test, rf_labels4))\n",
    "    rf_500_3_accuracy.append(accuracy_score(y_test, rf_labels4))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md5= RandomForestClassifier(n_estimators= 500, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred5= rf_md5.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels5= np.where(rf_pred5 < .1, 0, 1)\n",
    "    rf_500_5_recall.append(recall_score(y_test, rf_labels5))\n",
    "    rf_500_5_accuracy.append(accuracy_score(y_test, rf_labels5))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md6= RandomForestClassifier(n_estimators= 500, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred6= rf_md6.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels6= np.where(rf_pred6 < .1, 0, 1)\n",
    "    rf_500_7_recall.append(recall_score(y_test, rf_labels6))\n",
    "    rf_500_7_accuracy.append(accuracy_score(y_test, rf_labels6))\n",
    "    \n",
    "    \n",
    "    ###### 1000\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md7= RandomForestClassifier(n_estimators= 1000, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred7= rf_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels7= np.where(rf_pred7 < .1, 0, 1)\n",
    "    rf_1000_3_recall.append(recall_score(y_test, rf_labels7))\n",
    "    rf_1000_3_accuracy.append(accuracy_score(y_test, rf_labels7))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md8= RandomForestClassifier(n_estimators= 1000, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred8= rf_md8.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels8= np.where(rf_pred8 < .1, 0, 1)\n",
    "    rf_1000_5_recall.append(recall_score(y_test, rf_labels8))\n",
    "    rf_1000_5_accuracy.append(accuracy_score(y_test, rf_labels8))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md9= RandomForestClassifier(n_estimators= 1000, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred9= rf_md9.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels9= np.where(rf_pred9 < .1, 0, 1)\n",
    "    rf_1000_7_recall.append(recall_score(y_test, rf_labels9))\n",
    "    rf_1000_7_accuracy.append(accuracy_score(y_test, rf_labels9))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ####### 1500\n",
    "    \n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md10= RandomForestClassifier(n_estimators= 1500, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred10= rf_md10.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels10= np.where(rf_pred10 < .1, 0, 1)\n",
    "    rf_1500_3_recall.append(recall_score(y_test, rf_labels10))\n",
    "    rf_1500_3_accuracy.append(accuracy_score(y_test, rf_labels10))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md11= RandomForestClassifier(n_estimators= 1500, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred11= rf_md11.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels11= np.where(rf_pred11 < .1, 0, 1)\n",
    "    rf_1500_5_recall.append(recall_score(y_test, rf_labels11))\n",
    "    rf_1500_5_accuracy.append(accuracy_score(y_test, rf_labels11))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md12= RandomForestClassifier(n_estimators= 1500, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred12= rf_md12.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels12= np.where(rf_pred12 < .1, 0, 1)\n",
    "    rf_1500_7_recall.append(recall_score(y_test, rf_labels12))\n",
    "    rf_1500_7_accuracy.append(accuracy_score(y_test, rf_labels12))\n",
    "    \n",
    "    \n",
    "    ##### 2000\n",
    "    \n",
    "     #Buidling the model\n",
    "    rf_md13= RandomForestClassifier(n_estimators= 2000, max_depth= 3).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred13= rf_md13.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels13= np.where(rf_pred13 < .1, 0, 1)\n",
    "    rf_2000_3_recall.append(recall_score(y_test, rf_labels13))\n",
    "    rf_2000_3_accuracy.append(accuracy_score(y_test, rf_labels13))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md14= RandomForestClassifier(n_estimators= 2000, max_depth= 5).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred14= rf_md14.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels14= np.where(rf_pred14 < .1, 0, 1)\n",
    "    rf_2000_5_recall.append(recall_score(y_test, rf_labels14))\n",
    "    rf_2000_5_accuracy.append(accuracy_score(y_test, rf_labels14))\n",
    "    \n",
    "    #Buidling the model\n",
    "    rf_md15= RandomForestClassifier(n_estimators= 2000, max_depth= 7).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    rf_pred15= rf_md15.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    rf_labels15= np.where(rf_pred15 < .1, 0, 1)\n",
    "    rf_2000_7_recall.append(recall_score(y_test, rf_labels15))\n",
    "    rf_2000_7_accuracy.append(accuracy_score(y_test, rf_labels15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ae60a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 100,3: 0.864871794871795\n",
      "Average Accuracy for Random Forest model 100,3: 0.871460674157303\n",
      "Average Recall for Random Forest model 100,35: 0.8650000000000001\n",
      "Average Accuracy for Random Forest model 100,5: 0.8752434456928836\n",
      "Average Recall for Random Forest model 100,7: 0.863846153846154\n",
      "Average Accuracy for Random Forest model 100,7: 0.9015730337078653\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 100,3:', np.mean(rf_100_3_recall))\n",
    "print('Average Accuracy for Random Forest model 100,3:', np.mean(rf_100_3_accuracy))\n",
    "print('Average Recall for Random Forest model 100,35:', np.mean(rf_100_5_recall))\n",
    "print('Average Accuracy for Random Forest model 100,5:', np.mean(rf_100_5_accuracy))\n",
    "print('Average Recall for Random Forest model 100,7:', np.mean(rf_100_7_recall))\n",
    "print('Average Accuracy for Random Forest model 100,7:', np.mean(rf_100_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b650b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 500,3: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 500,3: 0.871516853932584\n",
      "Average Recall for Random Forest model 500,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 500,5: 0.8732771535580521\n",
      "Average Recall for Random Forest model 500,7: 0.8642307692307694\n",
      "Average Accuracy for Random Forest model 500,7: 0.9033333333333335\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 500,3:', np.mean(rf_500_3_recall))\n",
    "print('Average Accuracy for Random Forest model 500,3:', np.mean(rf_500_3_accuracy))\n",
    "print('Average Recall for Random Forest model 500,35:', np.mean(rf_500_5_recall))\n",
    "print('Average Accuracy for Random Forest model 500,5:', np.mean(rf_500_5_accuracy))\n",
    "print('Average Recall for Random Forest model 500,7:', np.mean(rf_500_7_recall))\n",
    "print('Average Accuracy for Random Forest model 500,7:', np.mean(rf_500_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e388a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 1000,3: 0.8650000000000001\n",
      "Average Accuracy for Random Forest model 1000,3: 0.8715355805243443\n",
      "Average Recall for Random Forest model 1000,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 1000,5: 0.8729962546816477\n",
      "Average Recall for Random Forest model 1000,7: 0.8644871794871796\n",
      "Average Accuracy for Random Forest model 1000,7: 0.902921348314607\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 1000,3:', np.mean(rf_1000_3_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,3:', np.mean(rf_1000_3_accuracy))\n",
    "print('Average Recall for Random Forest model 1000,35:', np.mean(rf_1000_5_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,5:', np.mean(rf_1000_5_accuracy))\n",
    "print('Average Recall for Random Forest model 1000,7:', np.mean(rf_1000_7_recall))\n",
    "print('Average Accuracy for Random Forest model 1000,7:', np.mean(rf_1000_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26af63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for Random Forest model 1500,3: 0.8646153846153847\n",
      "Average Accuracy for Random Forest model 1500,3: 0.8715543071161046\n",
      "Average Recall for Random Forest model 1500,35: 0.8647435897435899\n",
      "Average Accuracy for Random Forest model 1500,5: 0.8728651685393255\n",
      "Average Recall for Random Forest model 1500,7: 0.8643589743589745\n",
      "Average Accuracy for Random Forest model 1500,7: 0.903239700374532\n"
     ]
    }
   ],
   "source": [
    "print('Average Recall for Random Forest model 1500,3:', np.mean(rf_1500_3_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,3:', np.mean(rf_1500_3_accuracy))\n",
    "print('Average Recall for Random Forest model 1500,35:', np.mean(rf_1500_5_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,5:', np.mean(rf_1500_5_accuracy))\n",
    "print('Average Recall for Random Forest model 1500,7:', np.mean(rf_1500_7_recall))\n",
    "print('Average Accuracy for Random Forest model 1500,7:', np.mean(rf_1500_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Recall for Random Forest model 2000,3:', np.mean(rf_2000_3_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,3:', np.mean(rf_2000_3_accuracy))\n",
    "print('Average Recall for Random Forest model 2000,35:', np.mean(rf_2000_5_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,5:', np.mean(rf_2000_5_accuracy))\n",
    "print('Average Recall for Random Forest model 2000,7:', np.mean(rf_2000_7_recall))\n",
    "print('Average Accuracy for Random Forest model 2000,7:', np.mean(rf_2000_7_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6912618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_100_3_001_recall= list()\n",
    "ada_100_3_001_accuracy= list()\n",
    "ada_100_3_01_recall= list()\n",
    "ada_100_3_01_accuracy= list()\n",
    "ada_100_3_1_recall= list()\n",
    "ada_100_3_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_100_5_001_recall= list()\n",
    "ada_100_5_001_accuracy= list()\n",
    "ada_100_5_01_recall= list()\n",
    "ada_100_5_01_accuracy= list()\n",
    "ada_100_5_1_recall= list()\n",
    "ada_100_5_1_accuracy= list()\n",
    "\n",
    "ada_100_7_001_recall= list()\n",
    "ada_100_7_001_accuracy= list()\n",
    "ada_100_7_01_recall= list()\n",
    "ada_100_7_01_accuracy= list()\n",
    "ada_100_7_1_recall= list()\n",
    "ada_100_7_1_accuracy= list()\n",
    "\n",
    "ada_500_3_001_recall= list()\n",
    "ada_500_3_001_accuracy= list()\n",
    "ada_500_3_01_recall= list()\n",
    "ada_500_3_01_accuracy= list()\n",
    "ada_500_3_1_recall= list()\n",
    "ada_500_3_1_accuracy= list()\n",
    "\n",
    "ada_500_5_001_recall= list()\n",
    "ada_500_5_001_accuracy= list()\n",
    "ada_500_5_01_recall= list()\n",
    "ada_500_5_01_accuracy= list()\n",
    "ada_500_5_1_recall= list()\n",
    "ada_500_5_1_accuracy= list()\n",
    "\n",
    "ada_500_7_001_recall= list()\n",
    "ada_500_7_001_accuracy= list()\n",
    "ada_500_7_01_recall= list()\n",
    "ada_500_7_01_accuracy= list()\n",
    "ada_500_7_1_recall= list()\n",
    "ada_500_7_1_accuracy= list()\n",
    "\n",
    "ada_1000_3_001_accuracy= list()\n",
    "ada_1000_3_001_recall= list()\n",
    "ada_1000_3_01_accuracy= list()\n",
    "ada_1000_3_01_recall= list()\n",
    "ada_1000_3_1_accuracy= list()\n",
    "ada_1000_3_1_recall= list()\n",
    "\n",
    "ada_1000_5_001_recall= list()\n",
    "ada_1000_5_001_accuracy= list()\n",
    "ada_1000_5_01_recall= list()\n",
    "ada_1000_5_01_accuracy= list()\n",
    "ada_1000_5_1_recall= list()\n",
    "ada_1000_5_1_accuracy= list()\n",
    "\n",
    "ada_1000_7_001_recall= list()\n",
    "ada_1000_7_001_accuracy= list()\n",
    "ada_1000_7_01_recall= list()\n",
    "ada_1000_7_01_accuracy= list()\n",
    "ada_1000_7_1_recall= list()\n",
    "ada_1000_7_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_1500_3_001_recall= list()\n",
    "ada_1500_3_001_accuracy= list()\n",
    "ada_1500_3_01_recall= list()\n",
    "ada_1500_3_01_accuracy= list()\n",
    "ada_1500_3_1_recall= list()\n",
    "ada_1500_3_1_accuracy= list()\n",
    "\n",
    "ada_1500_5_001_recall= list()\n",
    "ada_1500_5_001_accuracy= list()\n",
    "ada_1500_5_01_recall= list()\n",
    "ada_1500_5_01_accuracy= list()\n",
    "ada_1500_5_1_recall= list()\n",
    "ada_1500_5_1_accuracy= list()\n",
    "\n",
    "ada_1500_7_001_recall= list()\n",
    "ada_1500_7_001_accuracy= list()\n",
    "ada_1500_7_01_recall= list()\n",
    "ada_1500_7_01_accuracy= list()\n",
    "ada_1500_7_1_recall= list()\n",
    "ada_1500_7_1_accuracy= list()\n",
    "\n",
    "\n",
    "ada_2000_3_001_recall= list()\n",
    "ada_2000_3_001_accuracy= list()\n",
    "ada_2000_3_01_recall= list()\n",
    "ada_2000_3_01_accuracy= list()\n",
    "ada_2000_3_1_recall= list()\n",
    "ada_2000_3_1_accuracy= list()\n",
    "\n",
    "ada_2000_5_001_recall= list()\n",
    "ada_2000_5_001_accuracy= list()\n",
    "ada_2000_5_01_recall= list()\n",
    "ada_2000_5_01_accuracy= list()\n",
    "ada_2000_5_1_recall= list()\n",
    "ada_2000_5_1_accuracy= list()\n",
    "\n",
    "ada_2000_7_001_recall= list()\n",
    "ada_2000_7_001_accuracy= list()\n",
    "ada_2000_7_01_recall= list()\n",
    "ada_2000_7_01_accuracy= list()\n",
    "ada_2000_7_1_recall= list()\n",
    "ada_2000_7_1_accuracy= list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad084a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Building Ada models\n",
    "\n",
    "for i in range(0,100):\n",
    "    #Splitting the Data\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, stratify= y)\n",
    "\n",
    "#### 100,3    \n",
    "    #Building the model\n",
    "    ada_md1= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred1= ada_md1.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels1= np.where(ada_pred1 < .1, 0, 1)\n",
    "    ada_100_3_001_recall.append(recall_score(y_test, ada_labels1))\n",
    "    ada_100_3_001_accuracy.append(accuracy_score(y_test, ada_labels1))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md2= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred2= ada_md2.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels2= np.where(ada_pred2 < .1, 0, 1)\n",
    "    ada_100_3_01_recall.append(recall_score(y_test, ada_labels2))\n",
    "    ada_100_3_01_accuracy.append(accuracy_score(y_test, ada_labels2))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md3= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred3= ada_md3.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels3= np.where(ada_pred3 < .1, 0, 1)\n",
    "    ada_100_3_1_recall.append(recall_score(y_test, ada_labels3))\n",
    "    ada_100_3_1_accuracy.append(accuracy_score(y_test, ada_labels3))\n",
    "    \n",
    "    \n",
    "### 100,5\n",
    "    #Building the model\n",
    "    ada_md4= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred4= ada_md4.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels4= np.where(ada_pred1 < .1, 0, 1)\n",
    "    ada_100_5_001_recall.append(recall_score(y_test, ada_labels4))\n",
    "    ada_100_5_001_accuracy.append(accuracy_score(y_test, ada_labels4))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md5= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred5= ada_md5.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels5= np.where(ada_pred5 < .1, 0, 1)\n",
    "    ada_100_5_01_recall.append(recall_score(y_test, ada_labels5))\n",
    "    ada_100_5_01_accuracy.append(accuracy_score(y_test, ada_labels5))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md6= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred6= ada_md6.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels6= np.where(ada_pred6 < .1, 0, 1)\n",
    "    ada_100_5_1_recall.append(recall_score(y_test, ada_labels6))\n",
    "    ada_100_5_1_accuracy.append(accuracy_score(y_test, ada_labels6))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 100,7\n",
    "    #Building the model\n",
    "    ada_md7= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred7= ada_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels7= np.where(ada_pred7 < .1, 0, 1)\n",
    "    ada_100_7_001_recall.append(recall_score(y_test, ada_labels7))\n",
    "    ada_100_7_001_accuracy.append(accuracy_score(y_test, ada_labels7))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md8= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred8= ada_md8.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels8= np.where(ada_pred8 < .1, 0, 1)\n",
    "    ada_100_7_01_recall.append(recall_score(y_test, ada_labels8))\n",
    "    ada_100_7_01_accuracy.append(accuracy_score(y_test, ada_labels8))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md9= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 100, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred9= ada_md9.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels9= np.where(ada_pred9 < .1, 0, 1)\n",
    "    ada_100_7_1_recall.append(recall_score(y_test, ada_labels9))\n",
    "    ada_100_7_1_accuracy.append(accuracy_score(y_test, ada_labels9))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #### 500,3    \n",
    "    #Building the model\n",
    "    ada_md10= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred10= ada_md10.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels10= np.where(ada_pred10 < .1, 0, 1)\n",
    "    ada_500_3_001_recall.append(recall_score(y_test, ada_labels10))\n",
    "    ada_500_3_001_accuracy.append(accuracy_score(y_test, ada_labels10))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md11= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred11= ada_md11.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels11= np.where(ada_pred11 < .1, 0, 1)\n",
    "    ada_500_3_01_recall.append(recall_score(y_test, ada_labels11))\n",
    "    ada_500_3_01_accuracy.append(accuracy_score(y_test, ada_labels11))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md12= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators=500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred12= ada_md12.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels12= np.where(ada_pred12 < .1, 0, 1)\n",
    "    ada_500_3_1_recall.append(recall_score(y_test, ada_labels12))\n",
    "    ada_500_3_1_accuracy.append(accuracy_score(y_test, ada_labels12))\n",
    "    \n",
    "    \n",
    "### 500,5\n",
    "    #Building the model\n",
    "    ada_md13= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred13= ada_md13.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels13= np.where(ada_pred13 < .1, 0, 1)\n",
    "    ada_500_5_001_recall.append(recall_score(y_test, ada_labels13))\n",
    "    ada_500_5_001_accuracy.append(accuracy_score(y_test, ada_labels13))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md14= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred14= ada_md14.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels14= np.where(ada_pred14 < .1, 0, 1)\n",
    "    ada_500_5_01_recall.append(recall_score(y_test, ada_labels14))\n",
    "    ada_500_5_01_accuracy.append(accuracy_score(y_test, ada_labels14))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md15= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred15= ada_md15.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels15= np.where(ada_pred6 < .1, 0, 1)\n",
    "    ada_500_5_1_recall.append(recall_score(y_test, ada_labels15))\n",
    "    ada_500_5_1_accuracy.append(accuracy_score(y_test, ada_labels15))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 500,7\n",
    "    #Building the model\n",
    "    ada_md16= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred16= ada_md7.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels16= np.where(ada_pred16 < .1, 0, 1)\n",
    "    ada_500_7_001_recall.append(recall_score(y_test, ada_labels16))\n",
    "    ada_500_7_001_accuracy.append(accuracy_score(y_test, ada_labels16))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md17= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred17= ada_md17.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels17= np.where(ada_pred17 < .1, 0, 1)\n",
    "    ada_500_7_01_recall.append(recall_score(y_test, ada_labels17))\n",
    "    ada_500_7_01_accuracy.append(accuracy_score(y_test, ada_labels17))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md45= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred45= ada_md45.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels45= np.where(ada_pred45 < .1, 0, 1)\n",
    "    ada_500_7_1_recall.append(recall_score(y_test, ada_labels45))\n",
    "    ada_500_7_1_accuracy.append(accuracy_score(y_test, ada_labels45))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### 1000,3    \n",
    "    #Building the model\n",
    "    ada_md18= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred18= ada_md18.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels18= np.where(ada_pred18 < .1, 0, 1)\n",
    "    ada_1000_3_001_recall.append(recall_score(y_test, ada_labels18))\n",
    "    ada_1000_3_001_accuracy.append(accuracy_score(y_test, ada_labels18))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md19= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred19= ada_md19.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels19= np.where(ada_pred19 < .1, 0, 1)\n",
    "    ada_1000_3_01_recall.append(recall_score(y_test, ada_labels19))\n",
    "    ada_1000_3_01_accuracy.append(accuracy_score(y_test, ada_labels19))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md20= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred20= ada_md20.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels20= np.where(ada_pred20 < .1, 0, 1)\n",
    "    ada_1000_3_1_recall.append(recall_score(y_test, ada_labels20))\n",
    "    ada_1000_3_1_accuracy.append(accuracy_score(y_test, ada_labels20))\n",
    "    \n",
    "    \n",
    "### 1000,5\n",
    "    #Building the model\n",
    "    ada_md21= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred21= ada_md21.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels21= np.where(ada_pred21 < .1, 0, 1)\n",
    "    ada_1000_5_001_recall.append(recall_score(y_test, ada_labels21))\n",
    "    ada_1000_5_001_accuracy.append(accuracy_score(y_test, ada_labels21))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md22= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred22= ada_md22.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels22= np.where(ada_pred22 < .1, 0, 1)\n",
    "    ada_500_5_01_recall.append(recall_score(y_test, ada_labels22))\n",
    "    ada_500_5_01_accuracy.append(accuracy_score(y_test, ada_labels22))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md23= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred23= ada_md23.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels23= np.where(ada_pred23 < .1, 0, 1)\n",
    "    ada_500_5_1_recall.append(recall_score(y_test, ada_labels23))\n",
    "    ada_500_5_1_accuracy.append(accuracy_score(y_test, ada_labels23))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 1000,7\n",
    "    #Building the model\n",
    "    ada_md24= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred24= ada_md24.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels24= np.where(ada_pred24 < .1, 0, 1)\n",
    "    ada_1000_7_001_recall.append(recall_score(y_test, ada_labels24))\n",
    "    ada_1000_7_001_accuracy.append(accuracy_score(y_test, ada_labels24))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md25= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred25= ada_md25.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels25= np.where(ada_pred25 < .1, 0, 1)\n",
    "    ada_1000_7_01_recall.append(recall_score(y_test, ada_labels25))\n",
    "    ada_1000_7_01_accuracy.append(accuracy_score(y_test, ada_labels25))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md26= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred26= ada_md26.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels26= np.where(ada_pred26 < .1, 0, 1)\n",
    "    ada_1000_7_1_recall.append(recall_score(y_test, ada_labels26))\n",
    "    ada_1000_7_1_accuracy.append(accuracy_score(y_test, ada_labels26))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#### 1500,3    \n",
    "    #Building the model\n",
    "    ada_md27= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred27= ada_md27.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels27= np.where(ada_pred27 < .1, 0, 1)\n",
    "    ada_1500_3_001_recall.append(recall_score(y_test, ada_labels27))\n",
    "    ada_1500_3_001_accuracy.append(accuracy_score(y_test, ada_labels27))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md28= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred28= ada_md28.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels28= np.where(ada_pred28 < .1, 0, 1)\n",
    "    ada_1500_3_01_recall.append(recall_score(y_test, ada_labels28))\n",
    "    ada_1500_3_01_accuracy.append(accuracy_score(y_test, ada_labels28))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md29= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred29= ada_md29.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels29= np.where(ada_pred29 < .1, 0, 1)\n",
    "    ada_1500_3_1_recall.append(recall_score(y_test, ada_labels29))\n",
    "    ada_1500_3_1_accuracy.append(accuracy_score(y_test, ada_labels29))\n",
    "    \n",
    "    \n",
    "### 1500,5\n",
    "    #Building the model\n",
    "    ada_md30= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred30= ada_md30.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels30= np.where(ada_pred30 < .1, 0, 1)\n",
    "    ada_1500_5_001_recall.append(recall_score(y_test, ada_labels30))\n",
    "    ada_1500_5_001_accuracy.append(accuracy_score(y_test, ada_labels30))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md31= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred31= ada_md31.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels31= np.where(ada_pred31 < .1, 0, 1)\n",
    "    ada_1500_5_01_recall.append(recall_score(y_test, ada_labels31))\n",
    "    ada_1500_5_01_accuracy.append(accuracy_score(y_test, ada_labels31))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md32= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred32= ada_md32.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels32= np.where(ada_pred32 < .1, 0, 1)\n",
    "    ada_1500_5_1_recall.append(recall_score(y_test, ada_labels32))\n",
    "    ada_1500_5_1_accuracy.append(accuracy_score(y_test, ada_labels32))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 1500,7\n",
    "    #Building the model\n",
    "    ada_md33= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred33= ada_md33.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels33= np.where(ada_pred33 < .1, 0, 1)\n",
    "    ada_1500_7_001_recall.append(recall_score(y_test, ada_labels33))\n",
    "    ada_1500_7_001_accuracy.append(accuracy_score(y_test, ada_labels33))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md34= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred34= ada_md34.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels34= np.where(ada_pred34 < .1, 0, 1)\n",
    "    ada_1500_7_01_recall.append(recall_score(y_test, ada_labels34))\n",
    "    ada_1500_7_01_accuracy.append(accuracy_score(y_test, ada_labels34))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md35= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 1500, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred35= ada_md35.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels35= np.where(ada_pred35 < .1, 0, 1)\n",
    "    ada_1500_7_1_recall.append(recall_score(y_test, ada_labels35))\n",
    "    ada_1500_7_1_accuracy.append(accuracy_score(y_test, ada_labels35))   \n",
    "    \n",
    "    \n",
    "#### 2000,3  \n",
    "    #Building the model\n",
    "    ada_md36= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred36= ada_md36.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels36= np.where(ada_pred36 < .1, 0, 1)\n",
    "    ada_1500_3_001_recall.append(recall_score(y_test, ada_labels36))\n",
    "    ada_1500_3_001_accuracy.append(accuracy_score(y_test, ada_labels36))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md37= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred37= ada_md37.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels37= np.where(ada_pred37 < .1, 0, 1)\n",
    "    ada_2000_3_01_recall.append(recall_score(y_test, ada_labels37))\n",
    "    ada_2000_3_01_accuracy.append(accuracy_score(y_test, ada_labels37))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md38= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 3), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred38= ada_md38.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels38= np.where(ada_pred38 < .1, 0, 1)\n",
    "    ada_2000_3_1_recall.append(recall_score(y_test, ada_labels38))\n",
    "    ada_2000_3_1_accuracy.append(accuracy_score(y_test, ada_labels38))\n",
    "    \n",
    "    \n",
    "### 2000,5\n",
    "    #Building the model\n",
    "    ada_md39= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred39= ada_md39.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels39= np.where(ada_pred39 < .1, 0, 1)\n",
    "    ada_2000_5_001_recall.append(recall_score(y_test, ada_labels39))\n",
    "    ada_2000_5_001_accuracy.append(accuracy_score(y_test, ada_labels39))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md40= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred40= ada_md40.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels40= np.where(ada_pred40 < .1, 0, 1)\n",
    "    ada_2000_5_01_recall.append(recall_score(y_test, ada_labels40))\n",
    "    ada_2000_5_01_accuracy.append(accuracy_score(y_test, ada_labels40))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md41= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 5), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred41= ada_md41.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels41= np.where(ada_pred41 < .1, 0, 1)\n",
    "    ada_2000_5_1_recall.append(recall_score(y_test, ada_labels41))\n",
    "    ada_2000_5_1_accuracy.append(accuracy_score(y_test, ada_labels41))\n",
    "    \n",
    "    \n",
    "    \n",
    "### 2000,7\n",
    "    #Building the model\n",
    "    ada_md42= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.001).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred42= ada_md42.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels42= np.where(ada_pred42 < .1, 0, 1)\n",
    "    ada_2000_7_001_recall.append(recall_score(y_test, ada_labels42))\n",
    "    ada_2000_7_001_accuracy.append(accuracy_score(y_test, ada_labels42))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md43= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.01).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred43= ada_md43.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels43= np.where(ada_pred34 < .1, 0, 1)\n",
    "    ada_2000_7_01_recall.append(recall_score(y_test, ada_labels43))\n",
    "    ada_2000_7_01_accuracy.append(accuracy_score(y_test, ada_labels43))\n",
    "    \n",
    "    #Building the model\n",
    "    ada_md44= AdaBoostClassifier(base_estimator= DecisionTreeClassifier(max_depth= 7), n_estimators= 2000, learning_rate=.1).fit(x_train, y_train)\n",
    "    #Predicting on the model\n",
    "    ada_pred44= ada_md44.predict_proba(x_test)[:,1]\n",
    "    #changing liklihoods to labels \n",
    "    ada_labels44= np.where(ada_pred44 < .1, 0, 1)\n",
    "    ada_2000_7_1_recall.append(recall_score(y_test, ada_labels44))\n",
    "    ada_2000_7_1_accuracy.append(accuracy_score(y_test, ada_labels44))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Recall for Ada model 2000,7,.1:', np.mean(ada_2000_7_1_recall))\n",
    "print('Average Accuracy for Ada model 2000, 7,.1:', np.mean(ada_2000_7_1_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

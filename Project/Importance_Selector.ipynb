{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46d5d19b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XGBoost' from 'sklearn.ensemble' (/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/ensemble/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1722/2324646367.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXGBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'XGBoost' from 'sklearn.ensemble' (/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/ensemble/__init__.py)"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, XGBoost\n",
    "\n",
    "\n",
    "s3= boto3.resource('s3')\n",
    "bucket_name= 'morgangant-bata-445-bucket'\n",
    "bucket= s3.Bucket(bucket_name)\n",
    "\n",
    "file_key= 'train.csv'\n",
    "\n",
    "bucket_object= bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "#reading the datefile\n",
    "project = pd.read_csv(file_content_stream)\n",
    "project.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e64155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping na values\n",
    "project = project.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b22f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances= list()\n",
    "for i in range (1,100):\n",
    "    ## Defining the input and taregt variables\n",
    "    x= project[['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemsVoids', 'scansWithoutRegistration', 'quanitityModification', 'scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']]\n",
    "    y= project['fraud']\n",
    "\n",
    "    #Splitting data into train and test\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2)\n",
    "\n",
    "    #Building Model\n",
    "    RF_md= RandomForestClassifier(n_estimators= 500).fit(x_train, y_train)\n",
    "\n",
    "    #Extracting the feature importances\n",
    "    importances.append(RF_md.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdc8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   0.267337\n",
       "totalScanTimeInSeconds       0.146603\n",
       "grandTotal                   0.069167\n",
       "lineItemsVoids               0.070835\n",
       "scansWithoutRegistration     0.054783\n",
       "quanitityModification        0.024785\n",
       "scannedLineItemsPerSecond    0.166051\n",
       "valuePerSecond               0.091405\n",
       "lineItemVoidsPerPosition     0.109034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(importances)\n",
    "a.columns= ['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemsVoids', 'scansWithoutRegistration', 'quanitityModification', 'scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']\n",
    "a.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4cf1ea8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1722/1635807678.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Creating RF model with depth 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mRF_md2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#Predictingon the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mRF_pred2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRF_md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Fixed batch size strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mcompute_batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m\"\"\"Shutdown the workers and free the shared memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;34m\"\"\"Determine the optimal batch size\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "\n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with depth 3\n",
    "    RF_md= RandomForestClassifier(max_depth= 3, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with depth 5\n",
    "    RF_md2= RandomForestClassifier(max_depth= 5, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with depth 5\n",
    "    RF_md3= RandomForestClassifier(max_depth= 7, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebce7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.8852380952380952\n",
      "Average Recall for model 2: 0.9371428571428569\n",
      "Average Recall for model 3: 0.9414285714285714\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a36113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 7\n",
    "\n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 7, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 7, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth= 7, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7759f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.9393333333333335\n",
      "Average Recall for model 2: 0.9387619047619048\n",
      "Average Recall for model 3: 0.9390952380952382\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236f5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 3\n",
    "    \n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 3, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 3, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth= 3, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac63b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.8792380952380954\n",
      "Average Recall for model 2: 0.8787619047619049\n",
      "Average Recall for model 3: 0.8791428571428573\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d013000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 5\n",
    "    \n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 5, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 5, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth=5, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c62c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.9297619047619048\n",
      "Average Recall for model 2: 0.9307619047619049\n",
      "Average Recall for model 3: 0.9306666666666668\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc3e50c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1722/194619618.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb \n",
    "\n",
    "results= list()\n",
    "\n",
    "for i in range(0,100):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 3, n_estimators= 500, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d13c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

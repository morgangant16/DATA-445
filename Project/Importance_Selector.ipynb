{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005fd2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.1-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from xgboost) (1.5.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b74725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemsVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quanitityModification</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemsVoids  \\\n",
       "0           5                    1054       54.70               7   \n",
       "1           3                     108       27.36               5   \n",
       "2           3                    1516       62.16               3   \n",
       "3           6                    1791       92.31               8   \n",
       "4           5                     430       81.53               3   \n",
       "\n",
       "   scansWithoutRegistration  quanitityModification  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "3                         4                      4                   0.016192   \n",
       "4                         7                      2                   0.062791   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  fraud  \n",
       "0        0.051898                  0.241379      0  \n",
       "1        0.253333                  0.357143      0  \n",
       "2        0.041003                  0.230769      0  \n",
       "3        0.051541                  0.275862      0  \n",
       "4        0.189605                  0.111111      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "s3= boto3.resource('s3')\n",
    "bucket_name= 'morgangant-bata-445-bucket'\n",
    "bucket= s3.Bucket(bucket_name)\n",
    "\n",
    "file_key= 'train.csv'\n",
    "\n",
    "bucket_object= bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "#reading the datefile\n",
    "project = pd.read_csv(file_content_stream)\n",
    "project.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f03a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping na values\n",
    "project = project.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20447e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances= list()\n",
    "for i in range (1,100):\n",
    "    ## Defining the input and taregt variables\n",
    "    x= project[['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemsVoids', 'scansWithoutRegistration', 'quanitityModification', 'scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']]\n",
    "    y= project['fraud']\n",
    "\n",
    "    #Splitting data into train and test\n",
    "    x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2)\n",
    "\n",
    "    #Building Model\n",
    "    RF_md= RandomForestClassifier(n_estimators= 500).fit(x_train, y_train)\n",
    "\n",
    "    #Extracting the feature importances\n",
    "    importances.append(RF_md.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be14aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   0.267337\n",
       "totalScanTimeInSeconds       0.146603\n",
       "grandTotal                   0.069167\n",
       "lineItemsVoids               0.070835\n",
       "scansWithoutRegistration     0.054783\n",
       "quanitityModification        0.024785\n",
       "scannedLineItemsPerSecond    0.166051\n",
       "valuePerSecond               0.091405\n",
       "lineItemVoidsPerPosition     0.109034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(importances)\n",
    "a.columns= ['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemsVoids', 'scansWithoutRegistration', 'quanitityModification', 'scannedLineItemsPerSecond', 'valuePerSecond', 'lineItemVoidsPerPosition']\n",
    "a.apply(np.mean, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70417a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1722/1635807678.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Creating RF model with depth 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mRF_md2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#Predictingon the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mRF_pred2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRF_md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Fixed batch size strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mcompute_batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m\"\"\"Shutdown the workers and free the shared memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;34m\"\"\"Determine the optimal batch size\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "\n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with depth 3\n",
    "    RF_md= RandomForestClassifier(max_depth= 3, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with depth 5\n",
    "    RF_md2= RandomForestClassifier(max_depth= 5, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with depth 5\n",
    "    RF_md3= RandomForestClassifier(max_depth= 7, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e50e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.8852380952380952\n",
      "Average Recall for model 2: 0.9371428571428569\n",
      "Average Recall for model 3: 0.9414285714285714\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594ce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 7\n",
    "\n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 7, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 7, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth= 7, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bfda3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.9393333333333335\n",
      "Average Recall for model 2: 0.9387619047619048\n",
      "Average Recall for model 3: 0.9390952380952382\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b40ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 3\n",
    "    \n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 3, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 3, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth= 3, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c685772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.8784285714285716\n",
      "Average Recall for model 2: 0.8790000000000001\n",
      "Average Recall for model 3: 0.8793333333333335\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163927fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying different number of trees\n",
    "md1_results= list()\n",
    "md2_results= list()\n",
    "md3_results= list()\n",
    "\n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "    \n",
    "#depth of 5\n",
    "    \n",
    "for i in range (0,1000):\n",
    "\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "\n",
    "    #Creating RF model with 100 estimators\n",
    "    RF_md= RandomForestClassifier(max_depth= 5, n_estimators= 100).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred= RF_md.predict_proba(x_test)[:,1]\n",
    "    RF_pred\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label= np.where(RF_pred < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model1_recall= recall_score(y_test, RF_label)\n",
    "    md1_results.append(Model1_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with with 300 estimators\n",
    "    RF_md2= RandomForestClassifier(max_depth= 5, n_estimators= 300).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred2= RF_md2.predict_proba(x_test)[:,1]\n",
    "    RF_pred2\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label2= np.where(RF_pred2 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model2_recall= recall_score(y_test, RF_label2)\n",
    "    md2_results.append(Model2_recall)\n",
    "\n",
    "\n",
    "    #Creating RF model with 500 estimators\n",
    "    RF_md3= RandomForestClassifier(max_depth=5, n_estimators= 500).fit(x_train, y_train)\n",
    "    #Predictingon the model\n",
    "    RF_pred3= RF_md3.predict_proba(x_test)[:,1]\n",
    "    RF_pred3\n",
    "    #Changling likleyhoods to labels\n",
    "    RF_label3= np.where(RF_pred3 < .1, 0, 1)\n",
    "    #Computing recall\n",
    "    Model3_recall= recall_score(y_test, RF_label3)\n",
    "    md3_results.append(Model3_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d318f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for model 1: 0.9297619047619048\n",
      "Average Recall for model 2: 0.9307619047619049\n",
      "Average Recall for model 3: 0.9306666666666668\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for model 1:', np.mean(md1_results))\n",
    "print('Average Recall for model 2:',np.mean(md2_results))\n",
    "print('Average Recall for model 3:',np.mean(md3_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d813a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth of 3 and LR .1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 3, n_estimators= 500, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 3, n_estimators= 300, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 3, n_estimators= 100, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d823589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.859952380952381\n",
      "Average Recall for xgb model: 0.8882857142857145\n",
      "Average Recall for xgb model: 0.9440952380952381\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64fbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth of 5 and LR .1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 5, n_estimators= 500, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 5, n_estimators= 300, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 5, n_estimators= 100, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c39e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8463809523809526\n",
      "Average Recall for xgb model: 0.8568571428571429\n",
      "Average Recall for xgb model: 0.8947619047619049\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "965c8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth of 7 and LR .1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 7, n_estimators= 500, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 7, n_estimators= 300, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 7, n_estimators= 100, learning_rate= .1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187d9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8502380952380955\n",
      "Average Recall for xgb model: 0.8572380952380955\n",
      "Average Recall for xgb model: 0.8828571428571429\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1c32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth 3 and LR 1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 3, n_estimators= 500, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 3, n_estimators= 300, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 3, n_estimators= 100, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9449643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8043333333333335\n",
      "Average Recall for xgb model: 0.8094761904761906\n",
      "Average Recall for xgb model: 0.8266666666666668\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b526c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth 5 anf LR 1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 5, n_estimators= 500, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 5, n_estimators= 300, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 5, n_estimators= 100, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c210c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8021904761904761\n",
      "Average Recall for xgb model: 0.8075714285714286\n",
      "Average Recall for xgb model: 0.8207619047619048\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ae121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth 7 and LR 1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 7, n_estimators= 500, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 7, n_estimators= 300, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 7, n_estimators= 100, learning_rate= 1, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b408c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.807904761904762\n",
      "Average Recall for xgb model: 0.8112380952380953\n",
      "Average Recall for xgb model: 0.8227142857142857\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253e8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth 3 and LR .8\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 3, n_estimators= 500, learning_rate= .8).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 3, n_estimators= 300, learning_rate= .8).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 3, n_estimators= 100, learning_rate= .8).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4d6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8107142857142858\n",
      "Average Recall for xgb model: 0.8170952380952382\n",
      "Average Recall for xgb model: 0.8357142857142857\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f271e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 5, n_estimators= 500, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 5, n_estimators= 300, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 5, n_estimators= 100, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d8eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8154285714285714\n",
      "Average Recall for xgb model: 0.8206190476190477\n",
      "Average Recall for xgb model: 0.8341428571428572\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef30caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#Define the input and target variable\n",
    "x= project[['trustLevel', 'scannedLineItemsPerSecond', 'totalScanTimeInSeconds', 'lineItemVoidsPerPosition', 'valuePerSecond']]\n",
    "y= project['fraud']\n",
    "\n",
    "results= list()\n",
    "results2= list()\n",
    "results3= list()\n",
    "\n",
    "#depth 7 and LR 1\n",
    "\n",
    "for i in range(0,1000):\n",
    "    #splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, stratify=y)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md= xgb.XGBClassifier(max_depth= 7, n_estimators= 500, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred= xgb_md.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label= np.where(xgb_pred < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall= recall_score(y_test, xgb_label)\n",
    "    results.append(xgb_recall)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md2= xgb.XGBClassifier(max_depth= 7, n_estimators= 300, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred2= xgb_md2.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label2= np.where(xgb_pred2 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall2= recall_score(y_test, xgb_label2)\n",
    "    results2.append(xgb_recall2)\n",
    "    \n",
    "    \n",
    "    #creating model\n",
    "    xgb_md3= xgb.XGBClassifier(max_depth= 7, n_estimators= 100, learning_rate= .8, ).fit(x_train, y_train)\n",
    "    #predicitng on the model\n",
    "    xgb_pred3= xgb_md3.predict_proba(x_test)[:,1]\n",
    "    #Changling likleyhoods to labels\n",
    "    xgb_label3= np.where(xgb_pred3 < .1, 0, 1)\n",
    "    #Computing recall and appending score\n",
    "    xgb_recall3= recall_score(y_test, xgb_label3)\n",
    "    results3.append(xgb_recall3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad3c07e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall for xgb model: 0.8206666666666668\n",
      "Average Recall for xgb model: 0.8258571428571428\n",
      "Average Recall for xgb model: 0.8361904761904763\n"
     ]
    }
   ],
   "source": [
    "#Computing averages\n",
    "print('Average Recall for xgb model:', np.mean(results))\n",
    "print('Average Recall for xgb model:', np.mean(results2))\n",
    "print('Average Recall for xgb model:', np.mean(results3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
